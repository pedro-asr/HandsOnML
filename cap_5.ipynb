{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 5: Máquinas de Vetores de Suporte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Qual é a ideia fundamental por trás das Máquinas de Vetores de Suporte (SVM)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia fundamental por trás das Máquinas de Vetores de Suporte (SVM, do inglês *Support Vector Machines*) é encontrar um hiperplano em um espaço de alta dimensão que separa os dados de diferentes classes com a maior margem possível. Em outras palavras, a SVM busca um limite de decisão que maximiza a distância (margem) entre os pontos de dados mais próximos de diferentes classes, chamados de vetores de suporte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. O que é um vetor de suporte?\n",
    "\n",
    "Um vetor de suporte é um ponto de dado em uma Máquina de Vetores de Suporte (SVM) que está localizado na borda da margem ou bem próximo a ela, sendo fundamental para definir o hiperplano de separação entre as classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Por que é importante dimensionar as entradas ao utilizar SVM?\n",
    "\n",
    "Dimensionar as entradas ao utilizar SVM é essencial para garantir que todas as variáveis tenham um impacto apropriado no modelo, melhorar a eficiência computacional e assegurar que o modelo seja robusto e generalize bem. Sem esse passo, a SVM pode produzir resultados subótimos e ser menos eficaz na tarefa de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Um classificador SVM pode produzir uma pontuação de confiança quando classifica uma instância? E quanto a uma probabilidade?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim, um classificador SVM pode produzir uma pontuação de confiança ao classificar uma instância. No entanto, a interpretação dessa pontuação e a obtenção de uma probabilidade requerem um processamento adicional.\n",
    "\n",
    "**Pontuação de Confiança:**\n",
    "   - A pontuação de confiança em uma SVM geralmente é dada pela distância da instância ao hiperplano de separação. Esta distância pode ser positiva ou negativa, dependendo de qual lado do hiperplano a instância está.\n",
    "   - Quanto maior a distância da instância ao hiperplano, maior a \"confiança\" da SVM na classificação dessa instância. Um valor positivo sugere uma classificação para uma classe, enquanto um valor negativo sugere a outra.\n",
    "\n",
    "**Probabilidade:**\n",
    "   - Por padrão, a SVM não fornece diretamente uma probabilidade de classificação, porque o objetivo principal da SVM é encontrar um hiperplano de separação com uma margem máxima, e não estimar probabilidades.\n",
    "   - No entanto, é possível calibrar a saída da SVM para obter probabilidades usando um método chamado **Platt Scaling**. Esse método ajusta uma função sigmoide sobre as pontuações de confiança da SVM para converter essas pontuações em probabilidades.\n",
    "\n",
    "Implementação do Platt Scaling:\n",
    "- No `scikit-learn`, por exemplo, ao treinar uma SVM com a classe `SVC` ou `LinearSVC`, você pode ativar o parâmetro `probability=True` para permitir que o modelo retorne probabilidades.\n",
    "- Isso faz com que o `scikit-learn` ajuste automaticamente um modelo de Platt Scaling durante o treinamento e permita que você chame o método `.predict_proba()` para obter as probabilidades.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Você deve utilizar a forma primal ou dual do problema SVM no treinamento de um modelo em um conjunto de treinamento com milhões de instâncias e centenas de características?\n",
    "\n",
    "Para um conjunto de dados com milhões de instâncias e centenas de características, você deve utilizar a forma primal do problema SVM, especialmente se estiver interessado em uma SVM linear. A forma primal é mais escalável e eficiente em termos computacionais para esse cenário, permitindo o treinamento do modelo de forma prática e rápida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Digamos que você treinou um classificador SVM com o kernel RBF. Parece que ele se subajusta ao conjunto de treinamento: você deve aumentar ou diminuir γ (gamma)? E quanto ao C?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Aumente `γ`:** Isso tornará o modelo mais sensível às instâncias de treinamento próximas, potencialmente melhorando seu ajuste.\n",
    "- **Aumente `C`:** Isso permitirá que o modelo minimize mais erros de classificação no conjunto de treinamento, tornando-o mais complexo.\n",
    "\n",
    "Esses ajustes devem ajudar a reduzir o subajuste do modelo, mas é importante fazer isso com cuidado para evitar overfitting, que é o ajuste excessivo aos dados de treinamento. A validação cruzada pode ser uma boa prática para encontrar os valores ideais de `γ` e `C`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Como você deve configurar os parâmetros QP (**H**, **f**, **A**, e **b**) utilizando um solucionador de QP *off-the-shelf* para resolver o problema do classificador SVM linear de margem suave?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver o problema do classificador SVM linear de margem suave utilizando um solucionador de Programação Quadrática (QP), você precisa configurar os parâmetros da seguinte forma:\n",
    "\n",
    "### Problema de SVM Linear de Margem Suave\n",
    "\n",
    "O problema de SVM de margem suave pode ser formulado como um problema de otimização quadrática da seguinte forma:\n",
    "\n",
    "$\n",
    "\\min_{\\mathbf{w}, b, \\boldsymbol{\\xi}} \\frac{1}{2} \\mathbf{w}^T \\mathbf{w} + C \\sum_{i=1}^{n} \\xi_i\n",
    "$\n",
    "\n",
    "sujeito a:\n",
    "\n",
    "$\n",
    "y_i(\\mathbf{w}^T \\mathbf{x}_i + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0, \\quad \\text{para } i = 1, \\dots, n\n",
    "$\n",
    "\n",
    "Aqui:\n",
    "- $\\mathbf{w}$ são os pesos do modelo,\n",
    "- $b$ é o termo de bias,\n",
    "- $\\xi_i$ são as variáveis de relaxamento (slack variables) para margens suaves,\n",
    "- $C$ é o parâmetro de regularização que controla o trade-off entre maximizar a margem e minimizar o erro de classificação.\n",
    "\n",
    "### Reformulação como QP\n",
    "\n",
    "Este problema pode ser reformulado como um problema de Programação Quadrática padrão:\n",
    "\n",
    "$\n",
    "\\min_{\\mathbf{z}} \\frac{1}{2} \\mathbf{z}^T H \\mathbf{z} + \\mathbf{f}^T \\mathbf{z}\n",
    "$\n",
    "\n",
    "sujeito a:\n",
    "\n",
    "$\n",
    "A \\mathbf{z} \\geq \\mathbf{b}\n",
    "$\n",
    "\n",
    "Onde $\\mathbf{z} = [\\mathbf{w}; b; \\boldsymbol{\\xi}]$ é o vetor que agrupa as variáveis de decisão ($\\mathbf{w}$, $b$ e $\\boldsymbol{\\xi}$).\n",
    "\n",
    "### Configuração dos Parâmetros QP\n",
    "\n",
    "Para configurar os parâmetros QP ($H$, $\\mathbf{f}$, $A$, $\\mathbf{b}$):\n",
    "\n",
    "1. **Matriz $H$**:\n",
    "   - $H$ é a matriz que define a parte quadrática da função de custo. Para o problema de SVM, $H$ terá a forma:\n",
    "     $\n",
    "     H = \\begin{bmatrix}\n",
    "     I & \\mathbf{0} & \\mathbf{0} \\\\\n",
    "     \\mathbf{0} & 0 & \\mathbf{0} \\\\\n",
    "     \\mathbf{0} & \\mathbf{0} & \\mathbf{0}\n",
    "     \\end{bmatrix}\n",
    "     $\n",
    "   - Aqui, $I$ é a matriz identidade de dimensão igual ao número de características, e as outras partes são zeros. Isso reflete que apenas os pesos $\\mathbf{w}$ têm uma contribuição quadrática no custo.\n",
    "\n",
    "2. **Vetor $\\mathbf{f}$**:\n",
    "   - $\\mathbf{f}$ é o vetor que define a parte linear da função de custo. Para o problema de SVM:\n",
    "     $\n",
    "     \\mathbf{f} = \\begin{bmatrix}\n",
    "     \\mathbf{0} \\\\\n",
    "     0 \\\\\n",
    "     C\\mathbf{1}\n",
    "     \\end{bmatrix}\n",
    "     $\n",
    "   - O vetor $\\mathbf{f}$ tem componentes iguais a $C$ para as variáveis $\\xi_i$, refletindo o termo de regularização.\n",
    "\n",
    "3. **Matriz $A$**:\n",
    "   - $A$ define as restrições lineares do problema. Para o SVM de margem suave, $A$ terá a forma:\n",
    "     $\n",
    "     A = \\begin{bmatrix}\n",
    "     \\text{diag}(y_i) \\mathbf{X} & \\mathbf{y} & -I \\\\\n",
    "     \\mathbf{0} & \\mathbf{0} & -I\n",
    "     \\end{bmatrix}\n",
    "     $\n",
    "   - Aqui, $\\mathbf{X}$ é a matriz de características, $\\mathbf{y}$ é o vetor de rótulos de classe, e $-I$ são as restrições de não negatividade para $\\xi_i$.\n",
    "\n",
    "4. **Vetor $\\mathbf{b}$**:\n",
    "   - $\\mathbf{b}$ define os limites das restrições. Neste caso:\n",
    "     $\n",
    "     \\mathbf{b} = \\begin{bmatrix}\n",
    "     \\mathbf{1} \\\\\n",
    "     \\mathbf{0}\n",
    "     \\end{bmatrix}\n",
    "     $\n",
    "   - O primeiro bloco de $\\mathbf{b}$ reflete a restrição $y_i (\\mathbf{w}^T \\mathbf{x}_i + b) \\geq 1 - \\xi_i$, e o segundo bloco impõe $\\xi_i \\geq 0$.\n",
    "\n",
    "### Resumo\n",
    "\n",
    "- **$H$**: Uma matriz que penaliza $\\mathbf{w}$ quadraticamente, sendo $\\mathbf{w}$ o vetor de pesos.\n",
    "- **$\\mathbf{f}$**: Um vetor que define a função de custo linear, com penalizações $C$ para $\\xi_i$.\n",
    "- **$A$**: Uma matriz que impõe as restrições de margem suave e não negatividade de $\\xi_i$.\n",
    "- $\\mathbf{b}$: Um vetor que define as restrições dos valores mínimos que as margens devem alcançar.\n",
    "\n",
    "Esses parâmetros configuram o problema de SVM linear de margem suave para ser resolvido por um solucionador de QP off-the-shelf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Treine um LinearSVC em um conjunto de dados linearmente separável. Depois, treine o SVC e um SGDClassifier no mesmo conjunto de dados. Veja se você consegue fazer com que eles produzam aproximadamente o mesmo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pedro\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.82, 0.818, 0.818)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar as bibliotecas necessárias\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Gerar um conjunto de dados linearmente separável\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, \n",
    "                           n_redundant=5, n_classes=2, random_state=42)\n",
    "\n",
    "# Criar e treinar o LinearSVC\n",
    "linear_svc = LinearSVC(max_iter=10000, random_state=42)\n",
    "linear_svc.fit(X, y)\n",
    "\n",
    "# Criar e treinar o SVC com kernel linear\n",
    "svc = SVC(kernel='linear', random_state=42)\n",
    "svc.fit(X, y)\n",
    "\n",
    "# Criar e treinar o SGDClassifier (que usa gradiente descendente estocástico)\n",
    "sgd_clf = make_pipeline(StandardScaler(), SGDClassifier(loss='hinge', max_iter=1000, random_state=42, learning_rate='constant', eta0=0.001))\n",
    "sgd_clf.fit(X, y)\n",
    "\n",
    "# Fazer previsões com os três modelos\n",
    "y_pred_linear_svc = linear_svc.predict(X)\n",
    "y_pred_svc = svc.predict(X)\n",
    "y_pred_sgd_clf = sgd_clf.predict(X)\n",
    "\n",
    "# Calcular a acurácia dos três modelos\n",
    "accuracy_linear_svc = accuracy_score(y, y_pred_linear_svc)\n",
    "accuracy_svc = accuracy_score(y, y_pred_svc)\n",
    "accuracy_sgd_clf = accuracy_score(y, y_pred_sgd_clf)\n",
    "\n",
    "accuracy_linear_svc, accuracy_svc, accuracy_sgd_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Treine um classificador SVM no conjunto de dados MNIST. Uma vez que os classificadores SVM são classificadores binários, você precisará utilizar um contra todos para classificar todos os 10 dígitos. Ajuste os hiperparâmetros utilizando pequenos conjuntos de validação para acelerar o processo. Qual acurácia você pode alcançar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar o conjunto de dados MNIST e separar no conjunto de treinamento e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando um SVM linear para a classificação utilizando a estratégia de um contra todos (*One-vs-the-Rest*, OvR). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pedro\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = LinearSVC(random_state=42)\n",
    "lin_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a acurácia do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348666666666666"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lin_clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia obtida foi de, aproximadamente, 83,5%, o que bem abaixo do desejado, indicando que um modelo linear não é o ideal a ser utilizado. Portanto, deve-se treinar um novo modelo, dessa vez não linear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9455333333333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float32))\n",
    "X_test_scaled = scaler.transform(X_test.astype(np.float32))\n",
    "\n",
    "svm_clf = SVC(gamma=\"scale\")\n",
    "svm_clf.fit(X_train_scaled[:10000], y_train[:10000])\n",
    "\n",
    "y_pred = svm_clf.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos realizar um ajuste nos hiperparâmentros para aumentar ainda mais a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END ......C=7.572101248423705, gamma=0.0824598722365575; total time=   0.2s\n",
      "[CV] END ......C=7.572101248423705, gamma=0.0824598722365575; total time=   0.2s\n",
      "[CV] END ......C=7.572101248423705, gamma=0.0824598722365575; total time=   0.3s\n",
      "[CV] END ..C=10.463904862635657, gamma=0.0031201559960186026; total time=   0.2s\n",
      "[CV] END ..C=10.463904862635657, gamma=0.0031201559960186026; total time=   0.2s\n",
      "[CV] END ..C=10.463904862635657, gamma=0.0031201559960186026; total time=   0.2s\n",
      "[CV] END .....C=5.100438901747019, gamma=0.09159181277853191; total time=   0.3s\n",
      "[CV] END .....C=5.100438901747019, gamma=0.09159181277853191; total time=   0.3s\n",
      "[CV] END .....C=5.100438901747019, gamma=0.09159181277853191; total time=   0.3s\n",
      "[CV] END ....C=6.324334784440685, gamma=0.019292074264351283; total time=   0.2s\n",
      "[CV] END ....C=6.324334784440685, gamma=0.019292074264351283; total time=   0.2s\n",
      "[CV] END ....C=6.324334784440685, gamma=0.019292074264351283; total time=   0.2s\n",
      "[CV] END .....C=3.815667775144103, gamma=0.00450895715321067; total time=   0.2s\n",
      "[CV] END .....C=3.815667775144103, gamma=0.00450895715321067; total time=   0.2s\n",
      "[CV] END .....C=3.815667775144103, gamma=0.00450895715321067; total time=   0.2s\n",
      "[CV] END ....C=9.26467683804453, gamma=0.0040128204227893455; total time=   0.2s\n",
      "[CV] END ....C=9.26467683804453, gamma=0.0040128204227893455; total time=   0.2s\n",
      "[CV] END ....C=9.26467683804453, gamma=0.0040128204227893455; total time=   0.2s\n",
      "[CV] END .....C=5.158752501669052, gamma=0.04141678008047755; total time=   0.3s\n",
      "[CV] END .....C=5.158752501669052, gamma=0.04141678008047755; total time=   0.3s\n",
      "[CV] END .....C=5.158752501669052, gamma=0.04141678008047755; total time=   0.3s\n",
      "[CV] END ..C=3.8120342302215073, gamma=0.0060930693867630795; total time=   0.2s\n",
      "[CV] END ..C=3.8120342302215073, gamma=0.0060930693867630795; total time=   0.3s\n",
      "[CV] END ..C=3.8120342302215073, gamma=0.0060930693867630795; total time=   0.2s\n",
      "[CV] END ....C=7.047048574267384, gamma=0.011145704843083123; total time=   0.3s\n",
      "[CV] END ....C=7.047048574267384, gamma=0.011145704843083123; total time=   0.2s\n",
      "[CV] END ....C=7.047048574267384, gamma=0.011145704843083123; total time=   0.2s\n",
      "[CV] END ...C=9.279705343380623, gamma=0.0017721075647461914; total time=   0.2s\n",
      "[CV] END ...C=9.279705343380623, gamma=0.0017721075647461914; total time=   0.2s\n",
      "[CV] END ...C=9.279705343380623, gamma=0.0017721075647461914; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVC(),\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002599F1BA550>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002599F13D190>},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "param = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rnd_search_cv = RandomizedSearchCV(svm_clf, param, n_iter=10, verbose=2, cv=3)\n",
    "rnd_search_cv.fit(X_train_scaled[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=9.279705343380623, gamma=0.0017721075647461914)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8599947252641863"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos treinar o modelo utilizando os valores de gamma e C que retornaram o melhor resultado e com todos os pontos do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=9.279705343380623, gamma=0.0017721075647461914)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9713"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Treine um regressor SVM no conjunto de dados imobiliários da Califórnia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro quadrático médio (RMSE): 0.57\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Carregar o conjunto de dados California Housing\n",
    "california = fetch_california_housing()\n",
    "\n",
    "# Dividir os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(california[\"data\"], california[\"target\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar os dados (importante para SVM)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Criar o regressor SVM\n",
    "svm_regressor = SVR(kernel='rbf', C=100, gamma='scale')\n",
    "\n",
    "# Treinar o modelo\n",
    "svm_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = svm_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Avaliar o modelo utilizando o erro quadrático médio\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "# Mostrar o resultado\n",
    "print(f\"Erro quadrático médio (RMSE): {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O erro quadrático obtido já está muito bom."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

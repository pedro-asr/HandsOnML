{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 6: Árvores de Decisão\n",
    "\n",
    "## Exercícios\n",
    "\n",
    "### 1. Qual é a profundidade aproximada de uma Árvore de Decisão treinada (sem restrições) em um conjunto com 1 milhão de instâncias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A profundidade seria proporcional ao valor do logaritmo do número de instâncias na base 2:\n",
    "$$P = log_2(N)$$\n",
    "Dessa forma, a profundidade seria igual a: \n",
    "$$log_2(10^6) = 20$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. O coeficiente Gini de um nó geralmente é menor ou maior do que o dos seus pais? Ele é geralmente menor/maior, ou sempre menor/maior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É sempre menor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. É uma boa ideia tentar diminuir seu `max_depth` se uma Árvore de Decisão estiver se sobreajustando ao conjunto de treinamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim, é uma boa ideia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. É uma boa ideia tentar dimensionar as características de entrada se uma Árvore de Decisão estiver se subajustando ao conjunto de treinamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Se treinar uma Árvore de Decisão em um conjunto de treinamento contendo 1 milhão de instâncias demora 1 hora, aproximadamente quanto tempo demorará para treinar outra Árvore de Decisão em um conjunto de treinamento contendo 10 milhões de instâncias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ordem de complexidade do treinamento de uma árvore de decisão balanceada é igual a $O(n\\times m log(m))$. Com isso pode-se realizar um regra de três para se obter o tempo de treinamento de uma árvore de decisão contendo 10 milhões de instâncias é:\n",
    "$$n \\times 10^6 \\times log(10^6) \\rightarrow 1 hora $$\n",
    "$$n \\times 10^7 \\times log(10^7) \\rightarrow X horas $$\n",
    "Apesar de não ser conhecido o número de características ($n$), como ele é constante para os dois conjuntos de treinamento, acaba não afetando a proporção. Com isso:\n",
    "$$X = \\frac{n \\times 10^7 \\times log(10^7) \\times 1}{n \\times 10^6 \\times log(10^6)}$$\n",
    "Logo, demorará cerca de 11 horas e 40 minutos para treinar a outra árvore de decisão. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Se o seu conjunto de treinamento contém 100 mil instâncias, a configuração `presort=True` acelerará o treinamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não, pois o ganho de velocidade de treinamento utilizando essa técnica só se faz válido quando o conjunto de treinamento contém um número pequeno de instâncias, cerca de até alguns milhares. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Treine e ajuste uma Árvore de Decisão para o conjunto de dados de luas.\n",
    "\n",
    "  a. Gere um conjunto de dados de luas utilizando `make_moons(n_samples=10000, noise=0.4)`.\n",
    "  \n",
    "  b. Com a utilização do `train_test_split()`, divida em um conjunto de treinamento e um conjunto de testes.\n",
    "  \n",
    "  c. Utilize a pesquisa de grade com validação cruzada (com a ajuda da classe `GridSearchCV`) para encontrar bons valores de hiperparâmetros para um  `DecisionTreeClassifier`. Dica: tente vários valores para `max_leaf_nodes`.\n",
    "  \n",
    "  d. Treine-o no conjunto completo de treinamento utilizando estes hiperparâmetros e meça o desempenho do seu modelo no conjunto de teste. Você deve obter aproximadamente 85% a 87% de acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados: {'max_leaf_nodes': 20, 'min_samples_split': 2}\n",
      "Acurácia no conjunto de teste: 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_leaf_nodes': [10, 20, 50, 100, 200, 500],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_tree = grid_search.best_estimator_\n",
    "print(\"Melhores hiperparâmetros encontrados:\", grid_search.best_params_)\n",
    "\n",
    "best_tree.fit(X_train, y_train)\n",
    "y_pred = best_tree.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia no conjunto de teste: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Cultive uma floresta.\n",
    "\n",
    " a. Continuando o exercício anterior, gere mil subconjuntos do conjunto de treinamento, cada um contendo 100 instâncias selecionadas aleatoriamente. Dica: você pode utilizar a classe `ShuffleSplit` do Scikit-Learn para isso.\n",
    "\n",
    " b. Treine uma Árvore de Decisão em cada subconjunto utilizando os melhores valores do hiperparâmetro encontrados acima. Avalie essas mil Árvores de Decisão no conjunto de testes. Uma vez treinadas em conjuntos menores, essas Árvores de Decisão provavelmente terão um desempenho pior do que a primeira, alcançando apenas 80% de acurácia.\n",
    " \n",
    " c. Agora vem a mágica. Gere as previsões das mil Árvores de Decisão e mantenha apenas a previsão mais frequente para cada instância do conjunto de testes (você pode utilizar a função `mode()` do SciPy para isso). Isso lhe dá *previsões dos votos majoritários* sobre o conjunto de testes.\n",
    " \n",
    " d. Avalie estas previsões no conjunto de teste: você deve obter uma acurácia ligeiramente maior que o seu primeiro modelo (cerca de 0,5 a 1,5% a mais). Parabéns, você treinou um classificador de Floresta Aleatória!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**a**. Gerar mil subconjuntos do conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_subsets = 1000\n",
    "subset_size = 100\n",
    "\n",
    "shuffle_split = ShuffleSplit(n_splits=n_subsets, train_size=subset_size, random_state=42)\n",
    "\n",
    "mini_sets = []\n",
    "\n",
    "for mini_train_index, mini_test_index in shuffle_split.split(X_train):\n",
    "    X_mini_train = X_train[mini_train_index]\n",
    "    y_mini_train = y_train[mini_train_index]\n",
    "    \n",
    "    mini_sets.append((X_mini_train, y_mini_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**b**. Treinar uma árvore de decisão em cada subconjunto e avaliar no conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8012284999999999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "\n",
    "forest = [clone(grid_search.best_estimator_) for _ in range(n_subsets)]\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
    "    tree.fit(X_mini_train, y_mini_train)\n",
    "    \n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** Gerar as previsões das mil árvores de decisão e usar a votação majoritária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.empty([n_subsets, len(X_test)], dtype = np.uint8)\n",
    "\n",
    "for tree_index, tree in enumerate(forest):\n",
    "    Y_pred[tree_index] = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "y_pred_majority, n_votes = mode(Y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** Avaliando a acurácia das previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_majority.reshape([-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
